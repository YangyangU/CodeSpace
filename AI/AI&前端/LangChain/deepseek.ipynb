{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ OPENAI_API_KEY: \u001b[32m\"sk-0b02bc9ff59c4a07af38ca1fa1999577\"\u001b[39m }"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "  env,\n",
    "};\n",
    "\n",
    "process.env;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Sure! Here's a joke for you:\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Why donâ€™t skeletons fight each other?  \\n\"\u001b[39m +\n",
       "      \u001b[32m\"Because they donâ€™t have the guts! ðŸ˜„\"\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Sure! Here's a joke for you:\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Why donâ€™t skeletons fight each other?  \\n\"\u001b[39m +\n",
       "    \u001b[32m\"Because they donâ€™t have the guts! ðŸ˜„\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m30\u001b[39m, promptTokens: \u001b[33m7\u001b[39m, totalTokens: \u001b[33m37\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "    modelName: \"deepseek-chat\",\n",
    "    configuration: {\n",
    "        baseURL: \"https://api.deepseek.com/v1\",\n",
    "    }\n",
    "})\n",
    "\n",
    "await chatModel.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
